{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "import nbimporter\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import langid # identify languages based on tweets\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "class NetworkAnalysis:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def Make_Graph(self,name):\n",
    "        print \"ashish\"\n",
    "        \n",
    "    def Extract_Username_And_Edges(self,data):  # for making the nodes of the graph  \n",
    "        nodes=set()\n",
    "        edges=[]\n",
    "        tweets=np.array(data['tweets'])\n",
    "        username=np.array(data['username'])\n",
    "       \n",
    "        for i in range(0,tweets.size):\n",
    "            nodes.add(username[i]) #adding the username into the set of nodes for the graph\n",
    "\n",
    "            # extracting tagged username from the tweets using Regular Expression\n",
    "            m = np.array(re.findall(\"(?:^|[ ])@([a-zA-Z]+)\",tweets[i]))\n",
    "            if len(m) :  # if the current tweet has any tagged any username\n",
    "                edges.append([username[i],m]) #adding the username into the set of nodes for the graph \n",
    "            for i in m:\n",
    "                nodes.add(i)\n",
    "        return nodes,edges\n",
    "    \n",
    "    def Make_Graph(self,nodes,edges):\n",
    "        UsernameMapping={}\n",
    "        # mapping the username to the vertex using dictonary\n",
    "        for i,data in enumerate(nodes):\n",
    "            UsernameMapping[data]=i\n",
    "#         return UsernameMapping\n",
    "        \n",
    "        \n",
    "        graph = np.zeros(shape=(len(nodes),len(nodes)))   # initializing the graph\n",
    "        \n",
    "        # making the adjacency matrix according to the edges\n",
    "        \n",
    "        for each_edge in edges:\n",
    "            source = each_edge[0] \n",
    "            for destination in each_edge[1]:\n",
    "                graph[ UsernameMapping[source] ][ UsernameMapping[destination] ]+=1\n",
    "                \n",
    "        return graph,UsernameMapping\n",
    "    \n",
    "    def Languages_Used(self,tweets):\n",
    "        \n",
    "        predicted_languages = [langid.classify(tweet) for tweet in tweets]\n",
    "\n",
    "        lang_df = pd.DataFrame(predicted_languages, columns=['language','value'])\n",
    "           \n",
    "        # show the top ten languages & their counts\n",
    "#         print(lang_df['language'].value_counts().head(10))\n",
    "       \n",
    "        # plot the counts for the top ten most commonly used languages\n",
    "        colors=sns.color_palette('hls', 10) \n",
    "        pd.Series(lang_df['language']).value_counts().head(10).plot(kind = \"bar\",\n",
    "                                                                figsize=(12,9),\n",
    "                                                                color=colors,\n",
    "                                                                fontsize=14,\n",
    "                                                                rot=45,\n",
    "                                                                title = \"Top 10 most common languages Used\")\n",
    "               \n",
    "        \n",
    "    def Most_Active_Users(self,data):\n",
    "        \n",
    "        tweeterites = data.groupby(['username']).count().reset_index()\n",
    "        tweeterites = tweeterites.sort_values(by='tweets').tail(10)\n",
    "        x = tweeterites['username']\n",
    "        y = tweeterites['tweets']\n",
    "        plt.xlabel('Twitter handle')\n",
    "        plt.ylabel('Number of tweets')\n",
    "        plt.title('Most number of tweets by user')\n",
    "        plt.xticks(range(10), x, rotation=45)\n",
    "        plt.bar(range(10), y, label='Most tweets+retweets by user')\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def Actual_And_Retweets(self,data):\n",
    "        retweets = []\n",
    "        actual_tweets = []\n",
    "        for user, tweet in zip(data['username'], data['tweets']):\n",
    "            match = re.search(r'^\\bRT\\b', tweet)\n",
    "            if match == None:\n",
    "                actual_tweets.append([user,tweet])\n",
    "            else:\n",
    "                retweets.append([user,tweet])   \n",
    "\n",
    "        actual_tweets = np.array(actual_tweets)\n",
    "        retweets = np.array(retweets)\n",
    "\n",
    "        plt.bar([1,2], [len(actual_tweets[:,1]), len(retweets[:,1])], align='center')\n",
    "        ax = plt.gca()\n",
    "        ax.set_xticks([1,2])\n",
    "        ax.set_xticklabels(['Actual Tweets', 'Retweets'])\n",
    "        plt.show()\n",
    "        \n",
    "    def Most_Mentioned_Users(self,Graph,InverseUsernameMapping):\n",
    "        \n",
    "        \n",
    "        Total_For_Each_User = Graph.sum(axis=0)  # Total number of times a particular user is mentioned in a comment\n",
    "        \n",
    "        Top_10_Users = sorted(range(len(Total_For_Each_User)), key=lambda i: Total_For_Each_User[i])[-10:]\n",
    "        \n",
    "        username_x = [ InverseUsernameMapping[i] for i in Top_10_Users]\n",
    "        total_times_mentioned_y = [ Total_For_Each_User[i] for i in Top_10_Users ]\n",
    "        \n",
    "        plt.xlabel('Twitter handle')\n",
    "        plt.ylabel('Number of Times Mentioned')\n",
    "        plt.title('Users that are Mentioned Most of the times')\n",
    "        plt.xticks(range(10), username_x, rotation=45)\n",
    "        plt.bar(range(10), total_times_mentioned_y, label='Most tweets+retweets by user')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "                \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    " \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "mat = [[\"ashish\",np.array([2,3])],[\"ram\",np.array([5,6,5,88])],[\"raman\",np.array([8])]]\n",
    "\n",
    "mat.append([\"daddu\",np.array([5,6,5,88])])\n",
    "\n",
    "\n",
    "\n",
    "# np.append(mat,[2,5,8],axis=0)\n",
    "# x = nmat.sum(axis=0)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
